// app/backend/server.js
const express = require('express');
const cors = require('cors');
const helmet = require('helmet');
const http = require('http');
const socketIo = require('socket.io');
const { MongoClient } = require('mongodb');
const axios = require('axios');
const cron = require('cron');

require('dotenv').config();

const app = express();
const server = http.createServer(app);
const io = socketIo(server, {
  cors: {
    origin: "http://localhost:3000",
    methods: ["GET", "POST"]
  }
});

const PORT = process.env.PORT || 5000;

// Configuration MongoDB
const MONGODB_URI = process.env.MONGODB_URI || 'mongodb://admin:bigdata123@mongodb:27017/bigdata?authSource=admin';
let mongoClient;

// Middleware
app.use(helmet());
app.use(cors());
app.use(express.json());
app.use(express.urlencoded({ extended: true }));

// Connexion Ã  MongoDB
async function connectToMongo() {
  try {
    mongoClient = new MongoClient(MONGODB_URI);
    await mongoClient.connect();
    console.log('âœ… Connexion Ã  MongoDB rÃ©ussie');
    return mongoClient.db('bigdata');
  } catch (error) {
    console.error('âŒ Erreur de connexion Ã  MongoDB:', error);
    return null;
  }
}

// Fonction pour vÃ©rifier le statut des services
async function checkServiceStatus() {
  const status = {
    hdfs: 'offline',
    yarn: 'offline',
    spark: 'offline',
    mongodb: 'offline',
    timestamp: new Date()
  };

  try {
    // VÃ©rification HDFS
    const hdfsResponse = await axios.get('http://namenode:9870/jmx?qry=Hadoop:service=NameNode,name=NameNodeStatus', { timeout: 5000 });
    status.hdfs = hdfsResponse.status === 200 ? 'online' : 'offline';
  } catch (error) {
    status.hdfs = 'error';
  }

  try {
    // VÃ©rification YARN
    const yarnResponse = await axios.get('http://namenode:8088/ws/v1/cluster/info', { timeout: 5000 });
    status.yarn = yarnResponse.status === 200 ? 'online' : 'offline';
  } catch (error) {
    status.yarn = 'error';
  }

  try {
    // VÃ©rification Spark
    const sparkResponse = await axios.get('http://spark-master:8080/json/', { timeout: 5000 });
    status.spark = sparkResponse.status === 200 ? 'online' : 'offline';
  } catch (error) {
    status.spark = 'error';
  }

  try {
    // VÃ©rification MongoDB
    if (mongoClient) {
      await mongoClient.db('bigdata').admin().ping();
      status.mongodb = 'online';
    }
  } catch (error) {
    status.mongodb = 'error';
  }

  return status;
}

// Routes API

// Route de santÃ©
app.get('/api/health', (req, res) => {
  res.json({ 
    status: 'OK', 
    timestamp: new Date(),
    services: ['hdfs', 'yarn', 'spark', 'mongodb'] 
  });
});

// Route pour le statut du cluster
app.get('/api/cluster/status', async (req, res) => {
  try {
    const status = await checkServiceStatus();
    res.json(status);
  } catch (error) {
    res.status(500).json({ error: 'Erreur lors de la vÃ©rification du statut' });
  }
});

// Route pour les mÃ©triques HDFS
app.get('/api/hdfs/metrics', async (req, res) => {
  try {
    const response = await axios.get('http://namenode:9870/jmx?qry=Hadoop:service=NameNode,name=FSNamesystemState');
    const metrics = response.data.beans[0];
    
    res.json({
      totalCapacity: metrics.CapacityTotal,
      usedCapacity: metrics.CapacityUsed,
      availableCapacity: metrics.CapacityRemaining,
      filesAndDirectories: metrics.FilesTotal,
      blocks: metrics.BlocksTotal,
      missingBlocks: metrics.MissingBlocks,
      corruptBlocks: metrics.CorruptBlocks
    });
  } catch (error) {
    res.status(500).json({ error: 'Impossible de rÃ©cupÃ©rer les mÃ©triques HDFS' });
  }
});

// Route pour les mÃ©triques YARN
app.get('/api/yarn/metrics', async (req, res) => {
  try {
    const response = await axios.get('http://namenode:8088/ws/v1/cluster/metrics');
    const metrics = response.data.clusterMetrics;
    
    res.json({
      totalMemory: metrics.totalMB,
      usedMemory: metrics.allocatedMB,
      availableMemory: metrics.availableMB,
      totalCores: metrics.totalVirtualCores,
      usedCores: metrics.allocatedVirtualCores,
      availableCores: metrics.availableVirtualCores,
      activeNodes: metrics.activeNodes,
      lostNodes: metrics.lostNodes,
      unhealthyNodes: metrics.unhealthyNodes
    });
  } catch (error) {
    res.status(500).json({ error: 'Impossible de rÃ©cupÃ©rer les mÃ©triques YARN' });
  }
});

// Route pour les mÃ©triques Spark
app.get('/api/spark/metrics', async (req, res) => {
  try {
    const response = await axios.get('http://spark-master:8080/json/');
    const data = response.data;
    
    res.json({
      status: data.status,
      workers: data.workers.length,
      aliveWorkers: data.aliveworkers,
      cores: data.cores,
      coresUsed: data.coresused,
      memory: data.memory,
      memoryUsed: data.memoryused,
      activeApps: data.activeapps.length,
      completedApps: data.completedapps.length
    });
  } catch (error) {
    res.status(500).json({ error: 'Impossible de rÃ©cupÃ©rer les mÃ©triques Spark' });
  }
});

// Route pour les donnÃ©es MongoDB
app.get('/api/data/sales', async (req, res) => {
  try {
    const db = mongoClient.db('bigdata');
    const limit = parseInt(req.query.limit) || 100;
    const skip = parseInt(req.query.skip) || 0;
    
    const sales = await db.collection('sales_data')
      .find({})
      .skip(skip)
      .limit(limit)
      .toArray();
    
    const total = await db.collection('sales_data').countDocuments();
    
    res.json({
      data: sales,
      total: total,
      page: Math.floor(skip / limit) + 1,
      totalPages: Math.ceil(total / limit)
    });
  } catch (error) {
    res.status(500).json({ error: 'Erreur lors de la rÃ©cupÃ©ration des donnÃ©es de vente' });
  }
});

// Route pour les analyses
app.get('/api/analytics/sales-by-region', async (req, res) => {
  try {
    const db = mongoClient.db('bigdata');
    
    const pipeline = [
      {
        $match: { status: 'completed' }
      },
      {
        $group: {
          _id: '$region',
          totalSales: { $sum: '$total_amount' },
          orderCount: { $sum: 1 },
          avgOrderValue: { $avg: '$total_amount' }
        }
      },
      {
        $sort: { totalSales: -1 }
      }
    ];
    
    const result = await db.collection('sales_data').aggregate(pipeline).toArray();
    res.json(result);
  } catch (error) {
    res.status(500).json({ error: 'Erreur lors de l\'analyse par rÃ©gion' });
  }
});

// Route pour l'analyse temporelle
app.get('/api/analytics/monthly-trends', async (req, res) => {
  try {
    const db = mongoClient.db('bigdata');
    
    const pipeline = [
      {
        $match: { status: 'completed' }
      },
      {
        $group: {
          _id: {
            year: { $year: '$date' },
            month: { $month: '$date' }
          },
          totalSales: { $sum: '$total_amount' },
          orderCount: { $sum: 1 }
        }
      },
      {
        $sort: { '_id.year': 1, '_id.month': 1 }
      },
      {
        $project: {
          period: {
            $concat: [
              { $toString: '$_id.year' },
              '-',
              {
                $cond: [
                  { $lt: ['$_id.month', 10] },
                  { $concat: ['0', { $toString: '$_id.month' }] },
                  { $toString: '$_id.month' }
                ]
              }
            ]
          },
          totalSales: 1,
          orderCount: 1
        }
      }
    ];
    
    const result = await db.collection('sales_data').aggregate(pipeline).toArray();
    res.json(result);
  } catch (error) {
    res.status(500).json({ error: 'Erreur lors de l\'analyse temporelle' });
  }
});

// Route pour exÃ©cuter des jobs Pig
app.post('/api/jobs/pig/execute', async (req, res) => {
  try {
    const { scriptName, parameters } = req.body;
    
    // Simulation d'exÃ©cution de job Pig
    const jobId = `pig_job_${Date.now()}`;
    
    // Ici, vous pourriez dÃ©clencher un vrai job Pig
    // Pour la dÃ©monstration, nous simulons
    
    res.json({
      jobId: jobId,
      status: 'submitted',
      scriptName: scriptName,
      timestamp: new Date(),
      message: 'Job Pig soumis avec succÃ¨s'
    });
    
    // Simulation de l'achÃ¨vement du job aprÃ¨s 10 secondes
    setTimeout(() => {
      io.emit('job-completed', {
        jobId: jobId,
        status: 'completed',
        timestamp: new Date()
      });
    }, 10000);
    
  } catch (error) {
    res.status(500).json({ error: 'Erreur lors de l\'exÃ©cution du job Pig' });
  }
});

// Route pour lister les jobs
app.get('/api/jobs/list', (req, res) => {
  // Simulation de la liste des jobs
  const jobs = [
    {
      id: 'pig_job_001',
      type: 'pig',
      name: 'sales_analysis.pig',
      status: 'completed',
      startTime: new Date(Date.now() - 3600000),
      endTime: new Date(Date.now() - 3000000),
      duration: 600000
    },
    {
      id: 'pig_job_002',
      type: 'pig',
      name: 'mongodb_integration.pig',
      status: 'running',
      startTime: new Date(Date.now() - 300000),
      endTime: null,
      duration: null
    },
    {
      id: 'spark_job_001',
      type: 'spark',
      name: 'data_processing',
      status: 'completed',
      startTime: new Date(Date.now() - 7200000),
      endTime: new Date(Date.now() - 6900000),
      duration: 300000
    }
  ];
  
  res.json(jobs);
});

// WebSocket pour les mises Ã  jour en temps rÃ©el
io.on('connection', (socket) => {
  console.log('Client connectÃ©:', socket.id);
  
  // Envoi du statut initial
  checkServiceStatus().then(status => {
    socket.emit('status-update', status);
  });
  
  socket.on('disconnect', () => {
    console.log('Client dÃ©connectÃ©:', socket.id);
  });
});

// TÃ¢che planifiÃ©e pour vÃ©rifier le statut toutes les 30 secondes
const statusJob = new cron.CronJob('*/30 * * * * *', async () => {
  try {
    const status = await checkServiceStatus();
    io.emit('status-update', status);
  } catch (error) {
    console.error('Erreur lors de la vÃ©rification du statut:', error);
  }
});

// DÃ©marrage du serveur
async function startServer() {
  try {
    // Connexion Ã  MongoDB
    await connectToMongo();
    
    // DÃ©marrage de la tÃ¢che de surveillance
    statusJob.start();
    
    // DÃ©marrage du serveur
    server.listen(PORT, () => {
      console.log(`ğŸš€ Serveur backend dÃ©marrÃ© sur le port ${PORT}`);
      console.log(`ğŸ“Š Dashboard disponible sur http://localhost:3000`);
      console.log(`ğŸ”§ API disponible sur http://localhost:${PORT}`);
    });
    
  } catch (error) {
    console.error('âŒ Erreur lors du dÃ©marrage du serveur:', error);
    process.exit(1);
  }
}

// Gestion de l'arrÃªt propre
process.on('SIGINT', async () => {
  console.log('ğŸ›‘ ArrÃªt du serveur...');
  
  if (statusJob) {
    statusJob.stop();
  }
  
  if (mongoClient) {
    await mongoClient.close();
  }
  
  server.close(() => {
    console.log('âœ… Serveur arrÃªtÃ© proprement');
    process.exit(0);
  });
});

// DÃ©marrage
startServer();